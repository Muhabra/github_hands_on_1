{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48935e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e80c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLogisticRegression():\n",
    "    \n",
    "    def __init__(self, num_iter=100, lr=0.01, bias=False, verbose=False):\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        self.lamda = 1/0.01\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "    \n",
    "    def _check_for_bais(self,X):\n",
    "        if self.bias == True:\n",
    "            x1 = np.ones(X.shape[0])\n",
    "        else:\n",
    "            x1 = np.zeros(X.shape[0])\n",
    "        \n",
    "        return np.concatenate([x1.reshape(-1,1),X],axis=1)\n",
    "        \n",
    "        \n",
    "    def _sigmoid_function(self,X):\n",
    "        linear_model = np.dot(X,self.theta)\n",
    "        \n",
    "        return 1/(1+np.exp(-linear_model))\n",
    "    \n",
    "    def _gradient_descent(self, X, error):\n",
    "        self.tmp = np.append(0,np.ones(X.shape[1]-1))\n",
    "        self.theta -= self.lr*(np.dot(error,X) + self.tmp*self.lamda*self.theta)/len(X)\n",
    "        \n",
    "    def _loss_function(self, y, y_pred):\n",
    "        return np.mean(-y*np.log(y_pred) -(1-y)*np.log(1-y_pred))+0.5*self.lamda*np.mean(self.theta[1:]**2)\n",
    "        \n",
    "    def fit(self, X, y, X_val=False, y_val=False):\n",
    "        \n",
    "        self.ylabel = np.unique(y)\n",
    "        \n",
    "        y = np.where(y==self.ylabel[0],0,1)\n",
    "        \n",
    "        if (type(y_val) != bool):\n",
    "            y_val = np.where(y_val==self.ylabel[0],0,1)\n",
    "        \n",
    "        X = self._check_for_bais(X)\n",
    "        \n",
    "        self.theta = np.random.rand(X.shape[1])\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            y_pred = self._sigmoid_function(X)\n",
    "            error = y_pred - y            \n",
    "            self.loss[i] = self._loss_function(y,y_pred)\n",
    "            \n",
    "            if (type(X_val) != bool):\n",
    "                val_X = self._check_for_bais(X_val)\n",
    "                val_ypred = self._sigmoid_function(val_X)\n",
    "                \n",
    "                self.val_loss[i] = self._loss_function(y_val,val_ypred)\n",
    "            \n",
    "            self._gradient_descent(X, error)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('n_iter:', i,\n",
    "                      'loss:',self.loss[i],\n",
    "                      'theta:',self.theta)\n",
    "            \n",
    "        np.save('theta', self.theta)            \n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self._check_for_bais(X)\n",
    "        y_pred = self._sigmoid_function(X)\n",
    "        \n",
    "        return np.where(y_pred<0.5,self.ylabel[0],self.ylabel[1])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self._check_for_bais(X)\n",
    "        return self._sigmoid_function(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95df45c",
   "metadata": {},
   "source": [
    "# Hypothetical function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7c3fe",
   "metadata": {},
   "source": [
    "- The assumed function for logistic regression is the assumed function for linear regression passed through the Sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f1e60",
   "metadata": {},
   "source": [
    "**This is implemented in the above class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc297a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid_function(self,X):\n",
    "    linear_model = np.dot(X,self.theta)\n",
    "\n",
    "    return 1/(1+np.exp(-linear_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5403dc",
   "metadata": {},
   "source": [
    "# Steepest descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13af7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_descent(self, X, error):\n",
    "    self.tmp = np.append(0,np.ones(X.shape[1]-1))\n",
    "    self.theta -= self.lr*(np.dot(error,X) + self.tmp*self.lamda*self.theta)/len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0bf83c",
   "metadata": {},
   "source": [
    "# Estimated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65dc91",
   "metadata": {},
   "source": [
    "- Please implement the estimation mechanism. Add to the predict method and predict_proba method included in the template of ScratchLogisticRegression class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ce57f",
   "metadata": {},
   "source": [
    "## Creating a datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "697c4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0adda79",
   "metadata": {},
   "source": [
    "**spliting the datasets into training and testing subsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673ec04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b16ff",
   "metadata": {},
   "source": [
    "**creating an instance of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176d6433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ibrahim\\AppData\\Local\\Temp\\ipykernel_32748\\2130757120.py:31: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(-y*np.log(y_pred) -(1-y)*np.log(1-y_pred))+0.5*self.lamda*np.mean(self.theta[1:]**2)\n",
      "C:\\Users\\Ibrahim\\AppData\\Local\\Temp\\ipykernel_32748\\2130757120.py:31: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.mean(-y*np.log(y_pred) -(1-y)*np.log(1-y_pred))+0.5*self.lamda*np.mean(self.theta[1:]**2)\n",
      "C:\\Users\\Ibrahim\\AppData\\Local\\Temp\\ipykernel_32748\\2130757120.py:24: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-linear_model))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels  [0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1\n",
      " 0 0 0]\n",
      "Probability: [9.05761552e-060 1.00000000e+000 1.00000000e+000 1.49678426e-016\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 9.93378469e-001 9.99996641e-001\n",
      " 1.00000000e+000 1.73753824e-005 3.51309627e-001 6.97658244e-110\n",
      " 1.00000000e+000 1.51313710e-218 1.28406256e-002 2.40697353e-286\n",
      " 4.74165303e-139 3.40564379e-029 1.00000000e+000 1.00000000e+000\n",
      " 2.17206058e-012 9.16507124e-002 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 0.00000000e+000 1.00000000e+000 1.18878026e-271\n",
      " 9.99983546e-001 3.96563445e-105 1.00000000e+000 4.16275811e-112\n",
      " 9.03637926e-006 3.88564623e-143 1.00000000e+000 7.81336935e-093\n",
      " 2.34736206e-031 1.00000000e+000 4.47243536e-102 1.00000000e+000\n",
      " 1.79692157e-005 3.03777611e-248 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 3.27324177e-051 4.05304687e-034 1.00000000e+000\n",
      " 2.58894917e-197 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 0.00000000e+000\n",
      " 4.84741629e-027 1.52597463e-139 1.00000000e+000 1.00000000e+000\n",
      " 3.01145764e-166 1.00000000e+000 0.00000000e+000 6.46618033e-162\n",
      " 9.41228075e-131 1.00000000e+000 2.54776953e-033 1.55703953e-180\n",
      " 1.00000000e+000 1.00000000e+000 1.08137306e-182 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.54311910e-056 2.48611972e-116 1.21253914e-171 1.00000000e+000\n",
      " 6.02773969e-062 1.00000000e+000 9.99992983e-001 1.00000000e+000\n",
      " 2.59640763e-183 2.45291619e-196 1.00000000e+000 1.43798446e-060\n",
      " 5.75405716e-007 9.94403952e-001 1.00000000e+000 1.00000000e+000\n",
      " 0.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 3.17923306e-203 1.00000000e+000 2.57353956e-068 1.84873981e-011\n",
      " 1.06511901e-037 1.00000000e+000 1.00000000e+000 1.68219591e-051\n",
      " 6.24275925e-159 1.00323517e-008]\n"
     ]
    }
   ],
   "source": [
    "l_regression = ScratchLogisticRegression(num_iter=1000, lr=0.001, verbose=False)\n",
    "l_regression.fit(X_train,y_train,X_test,y_test)\n",
    "y_pred_label = l_regression.predict(X_test)\n",
    "y_pred_proba = l_regression.predict_proba(X_test)\n",
    "\n",
    "print(\"Labels \",y_pred_label)\n",
    "print(\"Probability:\",y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4429a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
