{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b43335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da23d2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  OpenPorchSF  \\\n",
       "0          2003       196.0         706  ...           0           61   \n",
       "1          1976         0.0         978  ...         298            0   \n",
       "2          2002       162.0         486  ...           0           42   \n",
       "3          1970         0.0         216  ...           0           35   \n",
       "4          2000       350.0         655  ...         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "data=pd.read_csv('train.csv').select_dtypes(include='number')\n",
    "\n",
    "# handling of missing values\n",
    "data.isnull().sum()\n",
    "data = data.fillna(data.mean())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fbd30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(1460, 37), y shape:(1460,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "X = data.drop(['SalePrice'],axis=1).values\n",
    "y = data['SalePrice'].values\n",
    "\n",
    "X = np.log1p(X)\n",
    "y = np.log1p(y)\n",
    "\n",
    "print('X shape:{}, y shape:{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836dccd",
   "metadata": {},
   "source": [
    "# Blending scratch mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011b54b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105dd883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "blend:0.023\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions = list()\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions.append(model.predict(X_test))\n",
    "    \n",
    "predictions_ndarray = np.array(predictions)\n",
    "blend = np.mean(predictions_ndarray,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('blend:{:.3f}'.format(mean_squared_error(y_test,blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13168d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "blend:0.023\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "svr_model1 = SVR(C=1)\n",
    "svr_model2 = SVR(C=5)\n",
    "svr_model3 = SVR(C=10)\n",
    "svr_model1.fit(X_train,y_train)\n",
    "svr_model2.fit(X_train,y_train)\n",
    "svr_model3.fit(X_train,y_train)\n",
    "svr_pred1 = svr_model1.predict(X_test)\n",
    "svr_pred2 = svr_model2.predict(X_test)\n",
    "svr_pred3 = svr_model2.predict(X_test)\n",
    "    \n",
    "svr_blend = np.mean([svr_pred1,svr_pred2,svr_pred3],axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('blend:{:.3f}'.format(mean_squared_error(y_test,svr_blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "946d70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "blend:0.023\n"
     ]
    }
   ],
   "source": [
    "# example 3\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_trans = std_scaler.transform(X_train)\n",
    "X_test_trans = std_scaler.transform(X_test)\n",
    "\n",
    "models2 = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions2 = list()\n",
    "for model in models2:\n",
    "    model.fit(X_train_trans,y_train)\n",
    "    predictions2.append(model.predict(X_test_trans))\n",
    "    \n",
    "predictions_ndarray2 = np.array(predictions)\n",
    "blend2 = np.mean(predictions_ndarray2,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('blend:{:.3f}'.format(mean_squared_error(y_test,blend2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98883249",
   "metadata": {},
   "source": [
    "# Scratch mounting of bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0eb5cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train_bag.shape,y_test_bag.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de21186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of bagging pred:[12.23932577 11.99545486 11.56490218 11.01704575 11.95028506 12.56545219\n",
      " 12.59220741 11.86406303 12.27052756 12.36113397 12.0939682  11.12838367\n",
      " 12.18649386 12.82128078 12.35823762 11.64537706 11.62240874 11.72839201\n",
      " 12.32107768 11.73250238 11.65550567 11.82571449 12.42377148 12.65908722\n",
      " 11.47600934 12.20523297 11.72834793 12.17416771 12.86618536 11.86085426\n",
      " 11.71942545 11.70222618 11.65744956 11.53485066 11.90581371 12.73189308\n",
      " 11.76957728 11.32333622 12.60565707 11.64456544 11.97189583 11.90645494\n",
      " 11.55077765 11.74298774 12.11921553 12.09642135 11.75582306 12.04139342\n",
      " 12.41677083 12.387204   11.51670458 12.74536037 11.50486925 12.34734819\n",
      " 12.25089831 11.51290754 11.67917674 12.03161852 11.74564378 12.13721745\n",
      " 12.05648355 12.53183387 11.48373346 11.57012425 12.00872828 11.79789548\n",
      " 11.74946287 12.3373183  12.0838488  11.94699061 12.0301888  11.49884952\n",
      " 12.65849332 11.94814788 12.00256517 12.2646974  12.04329547 11.86209502\n",
      " 12.92208333 12.22241589 12.2218487  11.75390128 11.79758841 12.01696723\n",
      " 12.19488413 12.02820085 11.99980867 12.04381338 12.12966385 12.09982482\n",
      " 12.20024787 11.98374621 11.57957393 11.49854593 11.77168392 11.75484805\n",
      " 11.66828866 11.80456354 11.94970972 11.88906072 11.98585921 11.80841032\n",
      " 11.63764146 11.64858042 11.79048556 12.14972015 12.11081098 12.1586146\n",
      " 11.92171686 12.65311471 11.86217674 12.09030299 11.90105268 12.1900358\n",
      " 12.36422607 12.04217245 12.30038176 11.76253113 12.03873256 12.45486226\n",
      " 11.81249862 12.22269393 12.74241422 11.92100802 12.08302274 12.14661906\n",
      " 12.63815767 11.64641506 12.24518592 12.29632102 12.49906312 11.41171568\n",
      " 11.75751631 11.83854797 11.47063079 12.23350378 12.72587822 12.66768182\n",
      " 12.3851558  11.85316862 11.71901215 12.54425055 12.14054819 12.18017725\n",
      " 11.53200446 12.12776861 11.49762479 12.16087494 12.34359973 11.60348324\n",
      " 12.12636599 12.03315839 11.69002493 12.11512468 12.17955682 12.63604365\n",
      " 11.20881159 11.83236935 11.33126345 11.80387283 10.83409738 11.49062511\n",
      " 11.87403157 11.88615261 11.58470747 11.79566914 11.98063652 11.84503877\n",
      " 11.90689888 11.58543379 12.35661599 11.87725353 12.31573002 12.53100769\n",
      " 12.21220532 11.81543566 12.21781183 12.17304408 11.85984986 12.0558039\n",
      " 11.8343862  12.06805951 11.92785474 11.8925879  12.51976747 11.90503599\n",
      " 12.5343084  12.59249117 12.05836336 11.70744783 11.53627764 11.93276551\n",
      " 11.489222   12.24655159 11.78446624 12.50995396 12.33146388 11.97286827\n",
      " 11.90384482 11.03802792 12.23275246 12.34975594 12.10713942 12.06184845\n",
      " 12.46583316 11.70484107 12.14260578 12.62632821 12.40984822 12.34499726\n",
      " 12.1980879  11.63503197 11.96912846 11.6939772  12.5161836  12.44839643\n",
      " 11.72038431 11.37884673 12.21747651 11.13916403 12.6353742  11.69281289\n",
      " 11.92778764 12.21364068 11.6743006  11.72987818 12.17419009 12.0550451\n",
      " 11.94046769 12.02636426 11.70174296 12.11646218 11.5081532  11.73325161\n",
      " 12.64600432 11.67891512 12.59817909 11.69682064 11.80014501 12.62023138\n",
      " 12.72303774 11.87258673 11.8602322  11.92798931 11.82723683 11.68963334\n",
      " 11.96089235 11.91823821 11.98089947 11.99009577 11.63564484 11.59118072\n",
      " 12.09134308 12.08935    11.6225595  11.66598492 12.13748378 11.2683327\n",
      " 12.59225677 11.75557815 12.21777181 12.15255465 12.27384959 12.06339638\n",
      " 11.58558014 12.23770599 11.77071536 12.12709153 11.91828068 11.49541045\n",
      " 12.09590801 12.09942005 11.38813463 11.64913052 12.11537418 11.44792903\n",
      " 11.66630664 11.80076114 11.95899572 11.82833539 11.84049191 11.81463453\n",
      " 11.77338765 11.9215823  12.37112628 12.44323496 11.7120507  11.34078978\n",
      " 12.34518061 11.54463024 11.37364782 12.50343792]\n",
      "average of bagging mse:0.025\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "class BaggingScratch():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.predictions = list()\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        for model in models:\n",
    "            model.fit(X,y)\n",
    "    def predict(self,X):\n",
    "        predictions = list()\n",
    "        for model in self.models:\n",
    "            prediction = model.predict(X)\n",
    "            predictions.append(prediction)\n",
    "        self.predictions = np.mean(np.array(predictions),axis=0)\n",
    "        return self.predictions\n",
    "    def mse(self, y):\n",
    "        mse = (mean_squared_error(y,self.predictions))\n",
    "        return mse\n",
    "    \n",
    "\n",
    "bag = BaggingScratch(models)\n",
    "bag.fit(X_train,y_train)\n",
    "print(\"average of bagging pred:{}\".format(bag.predict(X_test)))\n",
    "print(\"average of bagging mse:{:.3f}\".format(bag.mse(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae5e77",
   "metadata": {},
   "source": [
    "# Stacking scratch mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71adf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X, y = datasets.make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset()\n",
    "# splitting into train and tests(used for base models)\n",
    "X_train_full, X_test_1, y_train_full, y_test_1 = train_test_split(X,y,test_size=0.5,random_state=1)\n",
    "\n",
    "# splitting into train and validations(used for ensemble model)\n",
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4363ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ibrahim\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Ibrahim\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# a function to return the models in a form of a tuple\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr',LinearRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeRegressor()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "# a function to fit and blend all of our models\n",
    "def fit_ensemble(models, X_train_1, X_val, y_train_1, y_val):\n",
    "    # fit and predict using the validation data\n",
    "    \n",
    "    # a list to hold the predicted data from the base model for the blender model\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        model.fit(X_train_1, y_train_1)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # defining our blender\n",
    "    blender = LinearRegression()\n",
    "    \n",
    "    # fitting our blender using our meta values and y validation set\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# a function to make predictions with our ensemble\n",
    "def pred_ensemble(models, blender, X_test_1):\n",
    "    # a list to hold te predictions for the blender\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        \n",
    "        # predicting using our base models\n",
    "        y_pred = model.predict(X_test_1)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # predicting using our blender\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, X_train_1, X_val, y_train_1, y_val)\n",
    "y_pred = pred_ensemble(models, blender, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6672c0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values used\n",
      "Train:(4000, 20) Val:(1000, 20) Test:(5000, 20)\n",
      "Accuracy score\n",
      "------------------\n",
      "Blended ensemble:0.023\n",
      "Logistic regression:0.110\n"
     ]
    }
   ],
   "source": [
    "# printing mse\n",
    "print(\"Values used\")\n",
    "print(\"Train:{} Val:{} Test:{}\".format(X_train_1.shape, X_val.shape, X_test_1.shape))\n",
    "print(\"Accuracy score\")\n",
    "print(\"------------------\")\n",
    "print(\"Blended ensemble:{:.3f}\".format(mean_squared_error(y_test_1,y_pred)))\n",
    "\n",
    "# on individual model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_1, y_train_1)\n",
    "y_pred1= model.predict(X_test_1)\n",
    "print(\"Logistic regression:{:.3f}\".format(mean_squared_error(y_test_1,y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f08bcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
